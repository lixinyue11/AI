{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## RGA + TF-IDF\n",
    "### RGAâ€¯+â€¯TFâ€‘IDF ååŒæµç¨‹\n",
    "1. ç”ŸæˆæŸ¥è¯¢æ‰©å†™ï¼šLLM äº§ç”Ÿ 2â€‘5 ä¸ªä¸åŒè§’åº¦çš„å…³é”®è¯è¡¨è¾¾ã€‚\n",
    "2. é€æ¡æ‰§è¡Œ TFâ€‘IDF æ£€ç´¢ å¾—åˆ°å€™é€‰æ–‡æ¡£ã€‚(â‘  ç»Ÿè®¡è¯é¢‘â€‘é€†æ–‡æ¡£é¢‘ç‡ TFÂ·IDF\n",
    "â‘¡ æŠŠæ–‡æ¡£ä¸æŸ¥è¯¢è¡¨ç¤ºæˆç¨€ç–å‘é‡\n",
    "â‘¢ ç”¨ä½™å¼¦ç›¸ä¼¼åº¦æ‰“åˆ†)\n",
    "3. èåˆå»é‡ï¼šåˆå¹¶å¤šæ¡æ£€ç´¢ç»“æœï¼Œå¯å†æŒ‰ TFâ€‘IDF åˆ†æ•°æˆ–ç®€å•è§„åˆ™æ’åºã€‚"
   ],
   "id": "b1158d252a8bc28d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-16T10:16:04.590081Z",
     "start_time": "2025-07-16T10:16:03.394978Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from typing import List\n",
    "\n",
    "from langchain_community.embeddings import DashScopeEmbeddings\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.docstore.document import Document\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ======= é…ç½® =======\n",
    "# ----------- é…ç½® -----------\n",
    "DASH_API_KEY = \"sk-0b8d48b85f1742829ef3032133375d3e\"\n",
    "EMBED_MODEL = \"text-embedding-v2\"\n",
    "LLM_MODEL = \"qwen2.5-72b-instruct\"\n",
    "\n",
    "embedding = DashScopeEmbeddings(model=EMBED_MODEL, dashscope_api_key=DASH_API_KEY)\n",
    "llm = ChatOpenAI(base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    "                 api_key=DASH_API_KEY,\n",
    "                 model=LLM_MODEL, temperature=0.7)\n",
    "TOP_K = 5\n",
    "EXPANSION_N = 3\n",
    "\n",
    "# ======= ç¤ºä¾‹æ–‡æ¡£ =======\n",
    "docs = [\n",
    "    Document(page_content=\"æ‰“å°æœºåº”åœ¨é€šé£ç¯å¢ƒä¸‹ä½¿ç”¨ï¼Œé˜²æ­¢è¿‡çƒ­ã€‚\", metadata={\"source\": \"safety\"}),\n",
    "    Document(page_content=\"å®‰è£…æ‰“å°é©±åŠ¨ç¨‹åºå‰ï¼Œè¯·ç¡®ä¿ç³»ç»Ÿå…¼å®¹ã€‚\", metadata={\"source\": \"setup\"}),\n",
    "    Document(page_content=\"æ‰“å°æœºä½¿ç”¨æ—¶è¯·è¿œç¦»æ°´æºï¼Œé¿å…çŸ­è·¯ã€‚\", metadata={\"source\": \"safety\"}),\n",
    "    Document(page_content=\"èŠ‚èƒ½æ‰“å°æ¨¡å¼å¯é™ä½è€—ç”µé‡ã€‚\", metadata={\"source\": \"efficiency\"}),\n",
    "    Document(page_content=\"é•¿æœŸä¸ä½¿ç”¨æ‰“å°æœºåº”æ‹”æ‰ç”µæºã€‚\", metadata={\"source\": \"safety\"}),\n",
    "]\n",
    "\n",
    "# ======= æ„å»º TF-IDF ç´¢å¼• =======\n",
    "corpus = [d.page_content for d in docs]\n",
    "vectorizer = TfidfVectorizer()\n",
    "doc_vecs = vectorizer.fit_transform(corpus)\n",
    "\n",
    "# ======= æŸ¥è¯¢æ‰©å†™å™¨ (RGA) =======\n",
    "def build_query_expander():\n",
    "    prompt = PromptTemplate.from_template(\n",
    "        \"\"\"ä½ æ˜¯ä¸€ä¸ªæŸ¥è¯¢å¢å¼ºåŠ©æ‰‹ï¼Œè¯·åŸºäºä»¥ä¸‹ç”¨æˆ·æŸ¥è¯¢ï¼Œç”Ÿæˆ {n} æ¡ä¸åŒè¡¨è¾¾çš„æ”¹å†™æŸ¥è¯¢ï¼Œæ¯æ¡ä¸€è¡Œï¼š\n",
    "        ç”¨æˆ·æŸ¥è¯¢ï¼š{query}\n",
    "        æ”¹å†™æŸ¥è¯¢ï¼š\"\"\"\n",
    "    )\n",
    "    return LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# ======= æ£€ç´¢å‡½æ•° =======\n",
    "def rga_tfidf_search(query: str, expander: LLMChain):\n",
    "    # (1) æŸ¥è¯¢æ‰©å†™\n",
    "    expanded = expander.run({\"query\": query, \"n\": EXPANSION_N})\n",
    "    queries = [query] + [l.strip(\" 123456.-\") for l in expanded.split(\"\\n\") if l.strip()]\n",
    "    print(\"ğŸ” æ‰©å±•æŸ¥è¯¢ï¼š\", queries)\n",
    "\n",
    "    # (2) TF-IDF æ£€ç´¢ + ç›¸ä¼¼åº¦æ‰“åˆ†\n",
    "    results = []\n",
    "    seen = set()\n",
    "    for q in queries:\n",
    "        q_vec = vectorizer.transform([q])\n",
    "        scores = cosine_similarity(q_vec, doc_vecs)[0]\n",
    "        sorted_indices = scores.argsort()[::-1]\n",
    "\n",
    "        for idx in sorted_indices[:TOP_K]:\n",
    "            doc = docs[idx]\n",
    "            score = scores[idx]\n",
    "            if doc.page_content not in seen:\n",
    "                results.append((doc, score))\n",
    "                seen.add(doc.page_content)\n",
    "\n",
    "    return sorted(results, key=lambda x: x[1], reverse=True)[:TOP_K]\n",
    "\n",
    "# ======= ä¸»ç¨‹åº =======\n",
    "if __name__ == \"__main__\":\n",
    "    query = \"èŠ‚èƒ½æ‰“å°æ¨¡å¼å¯é™ä½è€—ç”µé‡ï¼Ÿ\"\n",
    "    expander = build_query_expander()\n",
    "    results = rga_tfidf_search(query, expander)\n",
    "\n",
    "    print(f\"\\nğŸ¯ Top {len(results)} æ–‡æ¡£ï¼š\")\n",
    "    for i, (doc, score) in enumerate(results, 1):\n",
    "        print(f\"\\n[{i}] (score={score:.4f})\\n{doc.page_content}\")\n"
   ],
   "id": "a71a5332ab01332c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” æ‰©å±•æŸ¥è¯¢ï¼š ['èŠ‚èƒ½æ‰“å°æ¨¡å¼å¯é™ä½è€—ç”µé‡ï¼Ÿ', 'èŠ‚èƒ½æ‰“å°æ¨¡å¼èƒ½å¦å‡å°‘ç”µåŠ›æ¶ˆè€—ï¼Ÿ', 'ä½¿ç”¨èŠ‚èƒ½æ‰“å°æ¨¡å¼å¯ä»¥èŠ‚çœç”µå—ï¼Ÿ', 'å¼€å¯èŠ‚èƒ½æ‰“å°æ¨¡å¼å¯¹é™ä½åŠŸè€—æœ‰å¸®åŠ©å—ï¼Ÿ']\n",
      "\n",
      "ğŸ¯ Top 5 æ–‡æ¡£ï¼š\n",
      "\n",
      "[1] (score=1.0000)\n",
      "èŠ‚èƒ½æ‰“å°æ¨¡å¼å¯é™ä½è€—ç”µé‡ã€‚\n",
      "\n",
      "[2] (score=0.0000)\n",
      "é•¿æœŸä¸ä½¿ç”¨æ‰“å°æœºåº”æ‹”æ‰ç”µæºã€‚\n",
      "\n",
      "[3] (score=0.0000)\n",
      "æ‰“å°æœºä½¿ç”¨æ—¶è¯·è¿œç¦»æ°´æºï¼Œé¿å…çŸ­è·¯ã€‚\n",
      "\n",
      "[4] (score=0.0000)\n",
      "å®‰è£…æ‰“å°é©±åŠ¨ç¨‹åºå‰ï¼Œè¯·ç¡®ä¿ç³»ç»Ÿå…¼å®¹ã€‚\n",
      "\n",
      "[5] (score=0.0000)\n",
      "æ‰“å°æœºåº”åœ¨é€šé£ç¯å¢ƒä¸‹ä½¿ç”¨ï¼Œé˜²æ­¢è¿‡çƒ­ã€‚\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## RGA  BM25",
   "id": "209b6d42da4a698e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-16T10:17:06.656255Z",
     "start_time": "2025-07-16T10:17:04.174428Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os, re\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "from langchain_community.embeddings import DashScopeEmbeddings\n",
    "from rank_bm25 import BM25Okapi\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.docstore.document import Document\n",
    "from langchain_openai import ChatOpenAI\n",
    "# ----------- é…ç½® -----------\n",
    "DASH_API_KEY = \"sk-0b8d48b85f1742829ef3032133375d3e\"\n",
    "EMBED_MODEL = \"text-embedding-v2\"\n",
    "LLM_MODEL = \"qwen2.5-72b-instruct\"\n",
    "\n",
    "embedding = DashScopeEmbeddings(model=EMBED_MODEL, dashscope_api_key=DASH_API_KEY)\n",
    "LLM = ChatOpenAI(base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    "                 api_key=DASH_API_KEY,\n",
    "                 model=LLM_MODEL, temperature=0.7)\n",
    "\n",
    "EXPANSION_N = 3          # RGA ç”ŸæˆæŸ¥è¯¢æ•°\n",
    "TOP_K = 5                # æ¯æ¡å­æŸ¥è¯¢ BM25 å–å‰ k\n",
    "\n",
    "# =========== â‘¡ å¾®å‹è¯­æ–™ ===========\n",
    "RAW_DOCS = [\n",
    "    \"æ‰“å°æœºåº”åœ¨é€šé£ç¯å¢ƒä¸‹ä½¿ç”¨ï¼Œé˜²æ­¢è®¾å¤‡è¿‡çƒ­å¹¶é™ä½ç«ç¾é£é™©ã€‚\",\n",
    "    \"ç»´ä¿®æ‰“å°æœºå‰å¿…é¡»æ–­ç”µï¼Œä»¥é¿å…è§¦ç”µå’Œæœºæ¢°ä¼¤å®³ã€‚\",\n",
    "    \"èŠ‚èƒ½æ¨¡å¼å¯å°†æ‰“å°æœºèƒ½è€—é™ä½æœ€å¤š 30%ã€‚\",\n",
    "    \"ä½¿ç”¨åŸè£…è€—æå¯æé«˜æ‰“å°è´¨é‡å¹¶å»¶é•¿è®¾å¤‡å¯¿å‘½ã€‚\",\n",
    "    \"æ‰“å°å‰è¯·æ£€æŸ¥ç”µç¼†è¿æ¥æ˜¯å¦ç‰¢å›ºï¼Œé¿å…çŸ­è·¯éšæ‚£ã€‚\"\n",
    "]\n",
    "docs: List[Document] = [\n",
    "    Document(page_content=txt, metadata={\"id\": f\"d{i}\"}) for i, txt in enumerate(RAW_DOCS)\n",
    "]\n",
    "\n",
    "# =========== â‘¢ æç®€ä¸­æ–‡åˆ†è¯ ===========\n",
    "def tokenize(text: str) -> List[str]:\n",
    "    \"\"\"æ­£åˆ™åˆ‡è¯ï¼Œå¯æ›¿æ¢ä¸º jieba / pkuseg ä»¥è·å¾—æ›´å¥½åˆ†è¯æ•ˆæœ\"\"\"\n",
    "    return re.findall(r\"\\w+\", text.lower(), flags=re.U)\n",
    "\n",
    "# æ„å»º BM25 ç´¢å¼•\n",
    "corpus_tokens = [tokenize(d.page_content) for d in docs]\n",
    "bm25 = BM25Okapi(corpus_tokens)\n",
    "\n",
    "# =========== â‘£ æŸ¥è¯¢æ‰©å†™é“¾ï¼ˆRGAï¼‰ ===========\n",
    "expander = LLMChain(\n",
    "    llm=LLM,\n",
    "    prompt=PromptTemplate.from_template(\n",
    "        \"è¯·ä¸ºä»¥ä¸‹æŸ¥è¯¢ç”Ÿæˆ {n} æ¡ä¸åŒè¡¨è¾¾ï¼Œæ¯è¡Œä¸€ä¸ªï¼š\\næŸ¥è¯¢ï¼š{query}\\næ”¹å†™ï¼š\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# =========== â‘¤ RGA + BM25 æ£€ç´¢ ===========\n",
    "def rga_bm25_search(query: str) -> List[Tuple[Document, float]]:\n",
    "    # 1. LLM ç”Ÿæˆæ”¹å†™\n",
    "    exp = expander.run({\"query\": query, \"n\": EXPANSION_N})\n",
    "    queries = [query] + [q.strip(\" 123456.-\") for q in exp.split(\"\\n\") if q.strip()]\n",
    "    print(\"ğŸ” æ‰©å†™æŸ¥è¯¢:\", queries)\n",
    "\n",
    "    # 2. æ¯æ¡å­æŸ¥è¯¢ BM25 å¬å›\n",
    "    scored: Dict[str, float] = {}   # doc_id -> score\n",
    "    for q in queries:\n",
    "        q_tok = tokenize(q)\n",
    "        scores = bm25.get_scores(q_tok)\n",
    "        top_idx = scores.argsort()[-TOP_K:][::-1]     # æœ€é«˜ k\n",
    "        for idx in top_idx:\n",
    "            doc_id = docs[idx].metadata[\"id\"]\n",
    "            scored[doc_id] = max(scored.get(doc_id, 0), scores[idx])  # å–æœ€å¤§åˆ†\n",
    "\n",
    "    # 3. é™åºæ’åºå¹¶è¿”å›\n",
    "    results = sorted([(docs[int(d[1:])], s) for d, s in scored.items()],\n",
    "                     key=lambda x: x[1], reverse=True)\n",
    "    return results[:TOP_K]\n",
    "\n",
    "# =========== â‘¥ Demo è¿è¡Œ ===========\n",
    "if __name__ == \"__main__\":\n",
    "    user_query = \"æ‰“å°æœºèƒ½è€—é™ä½æœ€å¤š 30%ã€‚\"\n",
    "    for i, (doc, score) in enumerate(rga_bm25_search(user_query), 1):\n",
    "        print(f\"\\n[{i}] BM25={score:.2f} | {doc.page_content}\")\n"
   ],
   "id": "ef9b510a21a43d0d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” æ‰©å†™æŸ¥è¯¢: ['æ‰“å°æœºèƒ½è€—é™ä½æœ€å¤š 30%ã€‚', 'æ‰“å°æœºèŠ‚èƒ½æœ€é«˜è¾¾ 30%ã€‚', 'æ‰“å°æœºçš„èƒ½æºæ¶ˆè€—å‡å°‘ä¸è¶…è¿‡ 30%ã€‚', 'æ‰“å°æœºèƒ½æ•ˆæå‡ï¼Œæœ€å¤§èŠ‚èƒ½æ¯”ä¾‹ä¸º 30%ã€‚']\n",
      "\n",
      "[1] BM25=1.05 | èŠ‚èƒ½æ¨¡å¼å¯å°†æ‰“å°æœºèƒ½è€—é™ä½æœ€å¤š 30%ã€‚\n",
      "\n",
      "[2] BM25=0.00 | æ‰“å°å‰è¯·æ£€æŸ¥ç”µç¼†è¿æ¥æ˜¯å¦ç‰¢å›ºï¼Œé¿å…çŸ­è·¯éšæ‚£ã€‚\n",
      "\n",
      "[3] BM25=0.00 | ä½¿ç”¨åŸè£…è€—æå¯æé«˜æ‰“å°è´¨é‡å¹¶å»¶é•¿è®¾å¤‡å¯¿å‘½ã€‚\n",
      "\n",
      "[4] BM25=0.00 | ç»´ä¿®æ‰“å°æœºå‰å¿…é¡»æ–­ç”µï¼Œä»¥é¿å…è§¦ç”µå’Œæœºæ¢°ä¼¤å®³ã€‚\n",
      "\n",
      "[5] BM25=0.00 | æ‰“å°æœºåº”åœ¨é€šé£ç¯å¢ƒä¸‹ä½¿ç”¨ï¼Œé˜²æ­¢è®¾å¤‡è¿‡çƒ­å¹¶é™ä½ç«ç¾é£é™©ã€‚\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## RGA + SPLADE\n",
    "## https://github.com/naver/splade\n"
   ],
   "id": "dd5e44fa1b05d15"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "59a34cdb407f8a27"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
